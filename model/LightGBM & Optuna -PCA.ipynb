{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0cafc0-1993-411c-9247-d75ac091280b",
   "metadata": {},
   "source": [
    "# LightGBM & Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ce4a31-1781-4f46-a7ce-e2b1f6cedc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn: 0.24.1\n",
      "optuna      : 2.10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p scikit-learn,optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c55c2-1ec2-43fc-8c66-4a2acbc4b857",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2e92fa-1bf4-4435-a1f3-4e9613ec83d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (16268, 5)\n",
      "y_train.shape: (16268,)\n",
      "X_test.shape: (6973, 5)\n",
      "y_test.shape: (6973,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.read_csv('pcaX_without header.csv', header=None).values\n",
    "y = pd.read_csv('Y.csv', header=None).values.ravel().astype(int)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "#X_test = pd.read_csv('https://raw.githubusercontent.com/rasbt/stat451-machine-learning-fs21/main/hw02-starter/dataset/X_test.csv', header=None).values\n",
    "#y_test = pd.read_csv('https://raw.githubusercontent.com/rasbt/stat451-machine-learning-fs21/main/hw02-starter/dataset/y_test.csv', header=None).values.ravel().astype(int)\n",
    "\n",
    "print('X_train.shape:', X_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('X_test.shape:', X_test.shape)\n",
    "print('y_test.shape:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127e29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3b3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd1ee6f-7163-48ba-ba58-542191985c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 16268 3254\n"
     ]
    }
   ],
   "source": [
    "X_train_sub, X_valid, y_train_sub, y_valid = \\\n",
    "    train_test_split(X_train, y_train, test_size=0.2, random_state=1, stratify=y_train)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y_train.shape[0], y_valid.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae142588",
   "metadata": {},
   "source": [
    "## My Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd8b00",
   "metadata": {},
   "source": [
    "### LightGBM & Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06115cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna\n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef397c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "#optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "\n",
    "def objective(trial, X_train, y_train, cv=5):\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10, 100, 1000, 10000]),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.01]),\n",
    "    }\n",
    "    \n",
    "    cv_iterator = StratifiedKFold(n_splits=cv, shuffle=True, random_state=123)\n",
    "\n",
    "    cv_scores = np.zeros(cv)\n",
    "    for idx, (train_sub_idx, valid_idx) in enumerate(cv_iterator.split(X_train, y_train)):\n",
    "        \n",
    "        X_train_sub, X_valid = X_train[train_sub_idx], X_train[valid_idx]\n",
    "        y_train_sub, y_valid = y_train[train_sub_idx], y_train[valid_idx]\n",
    "\n",
    "        model = lightgbm.LGBMClassifier(objective=\"multi_logloss\", **param_grid)\n",
    "        model.fit(\n",
    "            X_train_sub,\n",
    "            y_train_sub,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            eval_metric=\"multi_logloss\",\n",
    "            verbose=-1,\n",
    "            early_stopping_rounds=50,\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial=trial, metric=\"multi_logloss\")\n",
    "            ],  # Add a pruning callback to eliminate unpromising candidates\n",
    "        )\n",
    "        preds = model.score(X_valid, y_valid)\n",
    "        \n",
    "        cv_scores[idx] = preds\n",
    "\n",
    "    return 1-np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a652ed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-05 14:05:27,634]\u001b[0m A new study created in memory with name: LGBM Classifier\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:06:51,814]\u001b[0m Trial 0 finished with value: 0.347246520681302 and parameters: {'n_estimators': 10000, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:06:53,122]\u001b[0m Trial 1 finished with value: 0.5124170190591408 and parameters: {'n_estimators': 10, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:08:12,713]\u001b[0m Trial 2 finished with value: 0.347246520681302 and parameters: {'n_estimators': 10000, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:09:36,958]\u001b[0m Trial 3 finished with value: 0.347246520681302 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:10:52,917]\u001b[0m Trial 4 finished with value: 0.347246520681302 and parameters: {'n_estimators': 10000, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:11:04,092]\u001b[0m Trial 5 finished with value: 0.37496883874957465 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:12:25,983]\u001b[0m Trial 6 finished with value: 0.347246520681302 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:13:56,374]\u001b[0m Trial 7 finished with value: 0.347246520681302 and parameters: {'n_estimators': 10000, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:14:07,357]\u001b[0m Trial 8 finished with value: 0.37496883874957465 and parameters: {'n_estimators': 100, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n",
      "\u001b[32m[I 2021-12-05 14:15:26,611]\u001b[0m Trial 9 finished with value: 0.347246520681302 and parameters: {'n_estimators': 10000, 'learning_rate': 0.01}. Best is trial 0 with value: 0.347246520681302.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n",
    "\n",
    "def func(trial):\n",
    "    return objective(trial, X_train, y_train)\n",
    "\n",
    "study.optimize(func, n_trials=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f461992",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value: 0.34725\n",
      "\tBest params:\n",
      "\t\tn_estimators: 10000\n",
      "\t\tlearning_rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tBest value: {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c586a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, n_estimators=10000,\n",
       "               objective='multi_logloss')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lightgbm.LGBMClassifier(objective=\"multi_logloss\", **study.best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3f5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.000\n",
      "Test Accuracy: 0.659\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {model.score(X_train, y_train):0.3f}\")\n",
    "print(f\"Test Accuracy: {model.score(X_test, y_test):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f274ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 38s ± 8.88 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "20.6 s ± 2.96 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model.fit(X_train, y_train) #training(fitting) time\n",
    "%timeit model.score(X_valid, y_valid) #test time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
