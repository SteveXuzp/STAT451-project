{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf24bd3-c1fc-4ead-a98a-54214e9e9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the data\n",
    "\n",
    "ori_data = pd.read_csv('X23241.csv')\n",
    "ori_data.drop(ori_data.columns.values[0], axis=1, inplace=True)\n",
    "\n",
    "X_train = pd.read_csv('X23241.csv').values[:,1:]\n",
    "y_train = pd.read_csv('Y23241.csv').values[:,1].ravel().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507e9427-be2d-46e9-a606-f25860b9e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid sizes: 18592 4649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data\n",
    "X_train_sub, X_valid, y_train_sub, y_valid = \\\n",
    "    train_test_split(X_train, y_train, test_size=0.2, random_state=1, stratify=y_train)\n",
    "\n",
    "print('Train/Valid sizes:', y_train_sub.shape[0], y_valid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5b6bdd-8d0d-484d-9896-bda3991c3b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28826454 0.22252553 0.19245387 0.10603844 0.06588928]\n",
      "[[-0.11447395 -0.48802539  0.10629545 -0.10310452 -0.07347723 -0.13478228\n",
      "   0.44601255 -0.3895188  -0.59378482]\n",
      " [-0.34697426  0.16817915  0.57992905  0.02601582  0.27997311 -0.34000309\n",
      "  -0.40117772 -0.39809669  0.03030707]\n",
      " [ 0.39959507 -0.09901385  0.05694173  0.6562734   0.58998156  0.16276772\n",
      "   0.07404582 -0.07113666 -0.10708937]\n",
      " [ 0.33901863  0.03472771  0.32713694 -0.25191764 -0.19657656  0.70809979\n",
      "  -0.21400659 -0.35245072 -0.05754382]\n",
      " [-0.73272082 -0.22959296 -0.131311    0.08176409  0.24943204  0.55950308\n",
      "  -0.01647461  0.07538013  0.07256517]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# pay attention to the data leaking, we can not use information on validation/test set\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_sub[:,0:9]) # only use pca for numerical variables\n",
    "\n",
    "X_scaled_sub = scaler.transform(X_train_sub[:,0:9]) \n",
    "X_scaled_valid = scaler.transform(X_valid[:,0:9]) #only use the information from training set\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_scaled_sub)\n",
    "X_new_train = pca.transform(X_scaled_sub)\n",
    "X_new_valid = pca.transform(X_scaled_valid)\n",
    "\n",
    "X_std_train = np.hstack((X_new_train, X_train_sub[:,10:]))\n",
    "X_std_valid = np.hstack((X_new_valid, X_valid[:,10:]))\n",
    "\n",
    "X_std_train = pd.DataFrame(data = X_std_train)\n",
    "X_std_valid = pd.DataFrame(data = X_std_valid)\n",
    "y_train_sub = pd.DataFrame(data = y_train_sub)\n",
    "y_valid = pd.DataFrame(data = y_valid)\n",
    "\n",
    "\n",
    "X_std_train.to_csv(\"pcaX_train.csv\", index = False)\n",
    "X_std_valid.to_csv(\"pcaX_test.csv\", index = False)\n",
    "y_train_sub.to_csv(\"pcay_train.csv\", index = False)\n",
    "y_valid.to_csv(\"pcay_test.csv\", index = False)\n",
    "\n",
    "print(pca.explained_variance_ratio_) # show explained variance ratio\n",
    "\n",
    "print(pca.components_) # show principal components"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
